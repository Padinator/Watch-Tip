{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "139c2115-ee9f-4425-aacd-e3bc8577bf8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import plotly.express as px\n",
    "import re\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "from collections import Counter\n",
    "from itertools import combinations\n",
    "from MulticoreTSNE import MulticoreTSNE as TSNE\n",
    "from pathlib import Path\n",
    "from sklearn.decomposition import PCA\n",
    "from typing import List\n",
    "\n",
    "# ---------- Import own python modules ----------\n",
    "project_dir = Path(os.path.abspath(\"\")).parents[0]\n",
    "sys.path.append(str(project_dir))\n",
    "\n",
    "import helper.variables as vars\n",
    "\n",
    "from database.genre import Genres\n",
    "from helper.file_system_interaction import load_object_from_file, save_object_in_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf8d1fb7-4408-44cd-8b01-cdceeb8e9adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants like seed etc.\n",
    "SEED = 1234\n",
    "cpu_kernel_for_tsne = 16\n",
    "# nan_movies = []\n",
    "\n",
    "# Define column names for DataFrames\n",
    "col_colours = \"colour\"\n",
    "col_colour_labels = \"colour_labels\"\n",
    "\n",
    "# Set seed\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# Define variables\n",
    "max_data_range = [100000]\n",
    "train_data_relationship_range = [0.85]\n",
    "history_len_range = [30]\n",
    "min_history_len_range = [20]\n",
    "fill_history_len_with_zero_movies_range = [False]\n",
    "fine_grained_extracting_range = [False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "618ae5d7-deb4-400a-949b-e6cbd8b225bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from database\n",
    "all_genres = Genres().get_all()\n",
    "genre_names = np.array([genre[\"name\"] for genre in all_genres.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c0ebb8d-fcb0-4849-8dca-89c8800ca352",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicates(arr: pd.Series) -> List[str]:\n",
    "    seen = set()\n",
    "    res = []\n",
    "\n",
    "    for colour_value, colour_label in arr:\n",
    "        label = str(colour_label)\n",
    "        if label not in seen:\n",
    "            res.append((colour_value, label))\n",
    "            seen.add(label)\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "def visualize_data_with_pca_or_tsne(path_to_store_tsne_dim_reduced_data: Path, components: int, df_original: pd.DataFrame, use_pca: bool=True,\n",
    "                                    time_dependence=False, point_size: int=10, title: str=\"\", ignore_columns: List[str]=[]) -> np.ndarray:\n",
    "    \"\"\"\n",
    "        Computes \"components\" many principal components for the passed\n",
    "        DataFrame \"df\" and plots the results. For this the number of\n",
    "        components must be 2 for 2D or 3 for 3D.\n",
    "        If column \"colour\" and \"colour_labels\" are already defined,\n",
    "        then the predfined ones will be used.\n",
    "        Pass is PCA should be used to compute principal components (True)\n",
    "        or if t-SNE should be used (False).\n",
    "    \"\"\"\n",
    "\n",
    "    global col_colours, col_colour_labels, cpu_kernel_for_tsne\n",
    "\n",
    "    assert 2 <= components <= 3\n",
    "\n",
    "    # Define some variables\n",
    "    col_size = \"size\"\n",
    "\n",
    "    # Compute principal components\n",
    "    tmp_df = df_original.loc[:, df_original.columns != col_colour_labels]  # Ignore column colour for computing the principal components\n",
    "    tmp_df = df_original[[col for col in df_original.columns if col not in [col_colours, col_colour_labels] + ignore_columns]]\n",
    "\n",
    "    if use_pca:\n",
    "        model = PCA(n_components=components, random_state=SEED)\n",
    "    else:\n",
    "        model = TSNE(n_components=components, n_jobs=cpu_kernel_for_tsne, random_state=SEED)  # Initialization \"random\" only supported\n",
    "\n",
    "    if not use_pca and os.path.exists(path_to_store_tsne_dim_reduced_data):  # Load t-SNE dimension reduced data from file\n",
    "        res = load_object_from_file(path_to_store_tsne_dim_reduced_data)\n",
    "    else:  # Compute t-SNE dimension reduced data from file\n",
    "        res = model.fit_transform(tmp_df.values)\n",
    "\n",
    "        if not use_pca:  # Save only with t-SNE\n",
    "            save_object_in_file(path_to_store_tsne_dim_reduced_data, res)  # Save dimension reduced data in file\n",
    "    df = pd.DataFrame(data=res, columns=[f\"c{i}\" for i in range(len(res[0]))])\n",
    "\n",
    "    if col_colours in df_original.columns:  # Use colours from original DataFrame\n",
    "        df[col_colours] = df_original[col_colours].values  # Use colours from original DataFrame\n",
    "\n",
    "    if use_pca:\n",
    "        print(f\"Variance/Amount of left/remaining information: {model.explained_variance_ratio_}, lost information: {1 - sum(model.explained_variance_ratio_)}\")\n",
    "        print(f\"Variance: {model.explained_variance_}\")\n",
    "\n",
    "    # Find all labels (= genres) for different colours (no duplicates)\n",
    "    colour_labels_and_colour_values = remove_duplicates(df_original[[col_colours, col_colour_labels]].values)  # Remove duplicates\n",
    "    colour_labels_and_colour_values = sorted(colour_labels_and_colour_values, key=lambda x: x[0])  # Sort labels by colour value\n",
    "    colour_labels = [label for _, label in colour_labels_and_colour_values]\n",
    "    colour_labels_str = [str(colour_label) for colour_label in colour_labels]\n",
    "    colours_ticks = [colour_value for colour_value, _ in colour_labels_and_colour_values]\n",
    "    print(\"Colour labels:\\n\", colour_labels)\n",
    "    print(\"Colour ticks:\\n\", colours_ticks)\n",
    "\n",
    "    # Set size and colour for each points\n",
    "    df[col_size] = [point_size for _ in range(df.shape[0])]  # Add size of each data point\n",
    "\n",
    "    if col_colours not in df.columns:  # Only add colours if it is not predefined\n",
    "        map_colour_labels_to_colours = dict(zip(colour_labels_str, colours))\n",
    "        df[col_colours] = [map_colour_labels_to_colours[str(colour_label)] for colour_label in df_original[col_colour_labels]]\n",
    "\n",
    "    # Plot graph\n",
    "    if components == 3:\n",
    "        fig = px.scatter_3d(df, x=\"c0\", y=\"c1\", z=\"c2\", size=col_size, color=col_colours)\n",
    "    else:\n",
    "        if time_dependence:  # Plot 3D with x-axis as time\n",
    "            df[\"time\"] = [i for i in range(1, df.shape[0] + 1)]\n",
    "            fig = px.scatter_3d(df, x=\"time\", y=\"c0\", z=\"c1\", size=col_size, color=col_colours)\n",
    "        else:\n",
    "            fig = px.scatter(df, x=\"c0\", y=\"c1\", size=col_size, color=col_colours)\n",
    "\n",
    "    fig.update_coloraxes(colorbar_tickvals=colours_ticks, colorbar_ticktext=colour_labels)\n",
    "    fig.update_layout(title_text=title, title_x=0.5)\n",
    "    fig.show(renderer='browser')\n",
    "\n",
    "\n",
    "def set_colour(label: str) -> int:\n",
    "    if \"input\" in label and \"target\" in label:\n",
    "        return 50\n",
    "    elif label.endswith(\"input\"):\n",
    "        return 100\n",
    "    elif label.endswith(\"target\"):\n",
    "        return 150\n",
    "    elif label.endswith(\"preds\"):\n",
    "        return 200\n",
    "    elif label == \"unused_movies\":\n",
    "        return 250\n",
    "    raise Exception(\"Label is unknown!\")\n",
    "\n",
    "\n",
    "def set_colour_label(label: str) -> int:\n",
    "    if \"input\" in label and \"target\" in label:\n",
    "        return \"Movie history + Target movie\"\n",
    "    elif label.endswith(\"input\"):\n",
    "        return \"Movie history\"\n",
    "    elif label.endswith(\"target\"):\n",
    "        return \"Target movie\"\n",
    "    elif label.endswith(\"preds\"):\n",
    "        return \"Predicted movie\"\n",
    "    elif label == \"unused_movies\":\n",
    "        return \"Unused movie\"\n",
    "    raise Exception(f\"Label {label} is unknown!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b76cd0d-e3f6-4302-8cca-ba641829ae7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(WindowsPath('C:/Users/Padinator/Downloads/Module/Master/Kint/Watch-Tip/model/results/100000_0.85_30_20_False_False_50_89127_32'),\n",
       "  30)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find all relevant model execution paths\n",
    "relevant_parameterizations = []\n",
    "relevant_model_execution_paths = []\n",
    "\n",
    "# Find all relevant model parameterizations\n",
    "for max_data in max_data_range:\n",
    "    for train_data_relationship in train_data_relationship_range:\n",
    "        for history_len in history_len_range:\n",
    "            for min_history_len in min_history_len_range:\n",
    "                for fill_history_len_with_zero_movies in fill_history_len_with_zero_movies_range:\n",
    "                    for fine_grained_extracting in fine_grained_extracting_range:\n",
    "                        save_dir = f\"{max_data}_{train_data_relationship}_{history_len}_{min_history_len}_{fill_history_len_with_zero_movies}_{fine_grained_extracting}\"\n",
    "                        relevant_parameterizations.append((save_dir, history_len))\n",
    "\n",
    "# Search for relevant model executino paths\n",
    "for root, dirs, files in os.walk(project_dir / \"model/results\"):  # Iterate over all model execution directories\n",
    "    for dir in dirs:\n",
    "        for parameterization, history_len in relevant_parameterizations:\n",
    "            if dir.startswith(parameterization):  # Check all directories, if it is a relevant model execution\n",
    "                relevant_model_execution_paths.append((Path(root) / dir, history_len))\n",
    "                break  # Skip other possible model exuections, use only first one\n",
    "\n",
    "relevant_model_execution_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "4cc01436-415a-4a77-a697-5696608902cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "Found 1 predictions with test data\n"
     ]
    }
   ],
   "source": [
    "# Load predictions from file\n",
    "predictions_with_test_data = [(path, load_object_from_file(path / \"predictions.pickle\"), history_len) for path, history_len in relevant_model_execution_paths]\n",
    "print(type(predictions_with_test_data))\n",
    "print(f\"Found {len(predictions_with_test_data)} predictions with test data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "719635cf-35f7-4bc2-809a-13cdc34ddb52",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Visualize all users' movie histories for each parameterization\n",
    "# for path, (X_test, y_test, predictions), history_len in predictions_with_test_data:\n",
    "#     dataframe_path = path / \"tsne_reduced_data.pickle\"\n",
    "#     print(f\"Visualize data of {path}\")\n",
    "\n",
    "#     # handable_data_len = 30000 // history_len  # Use only handable part of data\n",
    "#     handable_data_len = len(X_test)\n",
    "#     X_test = X_test[:handable_data_len]\n",
    "#     y_test = y_test[:handable_data_len]\n",
    "#     predictions = predictions[:handable_data_len]\n",
    "#     print(f\"Lengths of data (X_test, y_test, predictions): {len(X_test)}, {len(y_test)}, {len(predictions)}\")\n",
    "\n",
    "#     # Create DataFrames with test data (X and y) and predictions\n",
    "#     df_histories = pd.DataFrame(dict([(genre_name, [movie[i] for movies in X_test for movie in movies]) for i, genre_name in enumerate(genre_names)]))\n",
    "#     df_targets = pd.DataFrame(dict([(genre_name, [movie[i] for movie in y_test]) for i, genre_name in enumerate(genre_names)]))\n",
    "#     df_predictions = pd.DataFrame(dict([(genre_name, [movie[i] for movie in predictions]) for i, genre_name in enumerate(genre_names)]))\n",
    "\n",
    "#     # Define colours for all these data sets\n",
    "#     df_histories[col_colours] = [50] * df_histories.shape[0]\n",
    "#     df_targets[col_colours] = [100] * df_targets.shape[0]\n",
    "#     df_predictions[col_colours] = [150] * df_predictions.shape[0]\n",
    "\n",
    "#     # Define colour labels\n",
    "#     df_histories[col_colour_labels] = [\"Movie history\"] * df_histories.shape[0]\n",
    "#     df_targets[col_colour_labels] = [\"Target movie\"] * df_targets.shape[0]\n",
    "#     df_predictions[col_colour_labels] = [\"Predicted movie\"] * df_predictions.shape[0]\n",
    "\n",
    "#     # Merge DataFrames to one\n",
    "#     df = pd.concat([df_histories, df_targets, df_predictions])\n",
    "#     df.shape[0]\n",
    "\n",
    "#     # Visualize DataFrame\n",
    "#     print(f\"Size of DataFrame to visualize: {df.shape}\")\n",
    "#     visualize_data_with_pca_or_tsne(path_to_store_tsne_dim_reduced_data=dataframe_path, components=3, df_original=df, use_pca=False, title=f\"Predictions of {path}\")\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "388f725a-b342-4d88-aafe-bad6aef96d45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualize data of C:\\Users\\Padinator\\Downloads\\Module\\Master\\Kint\\Watch-Tip\\model\\results\\100000_0.85_30_20_False_False_50_89127_32\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 30, 32)            1856      \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 64)                24832     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 19)                1235      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 27,923\n",
      "Trainable params: 27,923\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Size of DataFrame to visualize: (100960, 23)\n",
      "Counter({'train_data_preds': 89127, 'train_data_targettrain_data_input': 5012, 'train_data_inputtrain_data_target': 4949, 'train_data_input': 1864, 'unused_movies': 5, 'train_data_target': 3})\n",
      "Counter({200: 89127, 50: 9961, 100: 1864, 250: 5, 150: 3})\n",
      "Counter({'Predicted movie': 89127, 'Movie history + Target movie': 9961, 'Movie history': 1864, 'Unused movie': 5, 'Target movie': 3})\n",
      "Variance/Amount of left/remaining information: [0.22139681 0.2048544  0.14195104], lost information: 0.43179775743932847\n",
      "Variance: [277.83897186 257.07929326 178.13956017]\n",
      "Colour labels:\n",
      " ['Movie history + Target movie', 'Movie history', 'Target movie', 'Predicted movie', 'Unused movie']\n",
      "Colour ticks:\n",
      " [50, 100, 150, 200, 250]\n",
      "\n",
      "Size of DataFrame to visualize: (27562, 23)\n",
      "Counter({'test_data_preds': 15729, 'test_data_input': 4898, 'test_data_inputtest_data_target': 3287, 'test_data_targettest_data_input': 3096, 'unused_movies': 478, 'test_data_target': 74})\n",
      "Counter({200: 15729, 50: 6383, 100: 4898, 250: 478, 150: 74})\n",
      "Counter({'Predicted movie': 15729, 'Movie history + Target movie': 6383, 'Movie history': 4898, 'Unused movie': 478, 'Target movie': 74})\n",
      "Variance/Amount of left/remaining information: [0.21228913 0.16675135 0.13508472], lost information: 0.4858748037000179\n",
      "Variance: [834.29533516 655.33203993 530.88234561]\n",
      "Colour labels:\n",
      " ['Movie history + Target movie', 'Movie history', 'Target movie', 'Predicted movie', 'Unused movie']\n",
      "Colour ticks:\n",
      " [50, 100, 150, 200, 250]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Visualize all users' movie histories for each parameterization\n",
    "for path, _ in relevant_model_execution_paths:\n",
    "    df_train_data = pd.read_pickle(path / \"train_data.dataframe\")\n",
    "    df_test_data = pd.read_pickle(path / \"test_data.dataframe\")\n",
    "    train_dataframe_path = path / \"tsne_reduced_data_train.pickle\"\n",
    "    test_dataframe_path = path / \"tsne_reduced_data_test.pickle\"\n",
    "    print(f\"Visualize data of {path}\")\n",
    "    model = tf.keras.models.load_model(path / \"lstm.keras\")\n",
    "    print(model.summary())\n",
    "    # print(df_train_data)\n",
    "\n",
    "    # Remove dubplicate points and change labels\n",
    "    train_data_no_duplicates = dict([(col, []) for col in df_train_data.columns])\n",
    "    test_data_no_duplicates = dict([(col, []) for col in df_train_data.columns])\n",
    "\n",
    "    for i, row in df_train_data.iterrows():\n",
    "        if row[\"movie\"] != -1 and row[\"movie\"] in train_data_no_duplicates[\"movie\"]:  # Movie is already in dict and no prediction\n",
    "            index = train_data_no_duplicates[\"movie\"].index(row[\"movie\"])\n",
    "            train_data_no_duplicates[\"label\"][index] += row[\"label\"]\n",
    "        else:  # Add new movies and predictions to dict\n",
    "            for col in df_train_data.columns:\n",
    "                train_data_no_duplicates[col].append(row[col])\n",
    "\n",
    "    for i, row in df_test_data.iterrows():\n",
    "        if row[\"movie\"] != -1 and row[\"movie\"] in test_data_no_duplicates[\"movie\"]:  # Movie is already in dict and no prediction\n",
    "            index = test_data_no_duplicates[\"movie\"].index(row[\"movie\"])\n",
    "            test_data_no_duplicates[\"label\"][index] += row[\"label\"]\n",
    "        else:  # Add new movies and predictions to dict\n",
    "            for col in df_test_data.columns:\n",
    "                test_data_no_duplicates[col].append(row[col])\n",
    "\n",
    "    df_train_data = pd.DataFrame(train_data_no_duplicates)\n",
    "    df_test_data = pd.DataFrame(test_data_no_duplicates)\n",
    "\n",
    "    # Define colours for all these data sets\n",
    "    df_train_data[col_colours] = [set_colour(label) for label in df_train_data[\"label\"]]\n",
    "    df_test_data[col_colours] = [set_colour(label) for label in df_test_data[\"label\"]]\n",
    "\n",
    "    # Define colour labels\n",
    "    df_train_data[col_colour_labels] = [set_colour_label(label) for label in df_train_data[\"label\"]]\n",
    "    df_test_data[col_colour_labels] = [set_colour_label(label) for label in df_test_data[\"label\"]]\n",
    "\n",
    "    # Visualize DataFrame\n",
    "    for dataframe_path, df, label in [(train_dataframe_path, df_train_data, \"train\"), (test_dataframe_path, df_test_data, \"test\")]:\n",
    "        print(f\"Size of DataFrame to visualize: {df.shape}\")\n",
    "        print(Counter(df[\"label\"].values))\n",
    "        print(Counter(df[col_colours].values))\n",
    "        print(Counter(df[col_colour_labels].values))\n",
    "        visualize_data_with_pca_or_tsne(path_to_store_tsne_dim_reduced_data=dataframe_path, components=3, df_original=df, use_pca=True, title=f\"Predictions of {path} for {label}\", ignore_columns=[\"movie\", \"label\"])\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa185c0a-f181-4a79-b2aa-90a6cc8c5509",
   "metadata": {},
   "source": [
    "# Results:\n",
    "- For train and test data: overall no movie is predicted very well and most movies are not predicted well at all\n",
    "- The two firgures look like two different shapes, one for input and output/target data and one for the predictions\n",
    "- It is a mystery why Tensorflow says that the model has an accuracy of 45%. There are two different shapes for the train data as well ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
